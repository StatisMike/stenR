[{"path":"https://statismike.github.io/stenR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 stenR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://statismike.github.io/stenR/articles/stenR_complete_tour.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Complete tour from data to results","text":"stenR main focus standardization normalization raw scores questionnaire survey basis Classical Test Theorem. Particularly psychology social studies common interpretate raw results measurement individual context. actuality, usually mistake . Instead, need evaluate score single questionee basis larger sample. can done finding place every individual raw score distribution representative sample. One can refer process normalization. Additional step phase standardize data even : quantile fitting standard scale. need noted rarely one answer one question (item) enough measure latent variable. Almost always need construct scale factor similar items gather behavioral sample. vital preprocessing phase transforming item-level raw scores scale-level can also handled functions available package, though feature main focus. Factor analysis actual construction scales factors beyond scope package. multiple useful solid tools available . Look upon psych /lavaan features. journey raw, questionnaire data normalized standardized results presented vignette.","code":""},{"path":"https://statismike.github.io/stenR/articles/stenR_complete_tour.html","id":"raw-questionnaire-data-preprocessing","dir":"Articles","previous_headings":"","what":"Raw questionnaire data preprocessing","title":"Complete tour from data to results","text":"work dataset available package: SLCS. contains answers 103 people Polish version Self-Liking Self-Competence Scale. can seen , contains demographical data questionee answers 16 diagnostic items. Authors measure prepared instructions calculating scores two subscales (Self-Liking Self-Competence). General Score , actually, just sum subscale scores. Self-Liking: 1R, 3, 5, 6R, 7R, 9, 11, 15R Self-Competence: 2, 4, 8R, 10R, 12, 13R, 14, 16 Items numbers suffixed R means, particular item need reversed summarizing rest calculate raw score subscale. ’s measure construction, answers items negatively correlated whole scale. steps can achieved using item-preprocessing functions stenR. Firstly, need create scale specification objects refer items available data name. need also list items need reversing () declare NA insertion strategies (default: insertion). Absolute minimum maximum score item need also provided step. allows correct computation even absolute values actually available data summed factor. situation happen first computation score table full representative sample, likely happen summarizing scores observations. scale specification objects created, can finally transform item-level raw scores scale-level ones using sum_items_to_scale() function. ScaleSpec CombScaleSpec object provided call used create one variable, taking account items need reversing (sub-scales case CombScaleSpec), well NA imputation strategies chosen scales. default columns available resulting data.frame, specifying retain argument can control . point successfully prepared data: now describes latent variables actually wanted measure, individual items. place next step: results normalization standardization. ScaleSpec CombScaleSpec objects specific print summary methods defined.","code":"library(stenR) #> Loading required package: R6 str(SLCS) #> 'data.frame':    103 obs. of  19 variables: #>  $ user_id: chr  \"damaged_kiwi\" \"unilateralised_anglerfish\" \"technical_anemonecrab\" \"temperate_americancurl\" ... #>  $ sex    : chr  \"M\" \"K\" \"K\" \"K\" ... #>  $ age    : int  30 31 22 26 22 17 27 24 20 19 ... #>  $ SLCS_1 : int  4 5 4 5 5 5 5 4 4 5 ... #>  $ SLCS_2 : int  2 2 4 3 2 3 1 5 2 1 ... #>  $ SLCS_3 : int  1 2 4 2 3 1 1 4 1 2 ... #>  $ SLCS_4 : int  2 1 4 2 4 2 1 4 4 2 ... #>  $ SLCS_5 : int  2 2 4 1 2 2 2 4 2 2 ... #>  $ SLCS_6 : int  4 4 5 5 5 5 1 2 5 4 ... #>  $ SLCS_7 : int  4 4 4 5 3 5 2 3 5 3 ... #>  $ SLCS_8 : int  4 5 4 5 4 5 5 4 4 5 ... #>  $ SLCS_9 : int  2 3 2 1 3 1 1 4 1 1 ... #>  $ SLCS_10: int  4 4 3 4 4 4 5 4 5 5 ... #>  $ SLCS_11: int  1 1 2 1 1 2 1 3 1 1 ... #>  $ SLCS_12: int  4 2 4 3 3 2 2 4 3 1 ... #>  $ SLCS_13: int  4 5 5 4 3 4 4 4 5 5 ... #>  $ SLCS_14: int  2 1 3 2 4 1 1 4 1 1 ... #>  $ SLCS_15: int  5 4 4 4 4 3 3 2 5 4 ... #>  $ SLCS_16: int  4 5 5 4 5 4 5 5 5 5 ... # create ScaleSpec objects for sub-scales SL_spec <- ScaleSpec(   name = \"Self-Liking\",   item_names = c(\"SLCS_1\", \"SLCS_3\", \"SLCS_5\", \"SLCS_6\", \"SLCS_7\",                   \"SLCS_9\", \"SLCS_11\", \"SLCS_15\"),   min = 1,   max = 5,   reverse = c(\"SLCS_1\", \"SLCS_6\", \"SLCS_7\", \"SLCS_15\") )  SC_spec <- ScaleSpec(   name = \"Self-Competence\",   item_names = c(\"SLCS_2\", \"SLCS_4\", \"SLCS_8\", \"SLCS_10\", \"SLCS_12\",                  \"SLCS_13\", \"SLCS_14\", \"SLCS_16\"),   min = 1,   max = 5,   reverse = c(\"SLCS_8\", \"SLCS_10\", \"SLCS_13\") )  # create CombScaleSpec object for general scale using single-scale  # specification GS_spec <- CombScaleSpec(   name = \"General Score\",   SL_spec,   SC_spec )  print(SL_spec) #> <ScaleSpec>: 'Self-Liking' #> No. items: 8 (4 reversed) #> NA imputation method: asis  #> NA literal value: NA print(SC_spec) #> <ScaleSpec>: 'Self-Competence' #> No. items: 8 (3 reversed) #> NA imputation method: asis  #> NA literal value: NA print(GS_spec) #> <CombScaleSpec>: 'General Score' #> No. items total: 16 #>  #> Underlying objects: #> <ScaleSpec>: Self-Liking #> <ScaleSpec>: Self-Competence summed_data <- sum_items_to_scale(   data = SLCS,   SL_spec,   SC_spec,   GS_spec,   retain = c(\"user_id\", \"sex\") )  str(summed_data) #> 'data.frame':    103 obs. of  5 variables: #>  $ user_id        : chr  \"damaged_kiwi\" \"unilateralised_anglerfish\" \"technical_anemonecrab\" \"temperate_americancurl\" ... #>  $ sex            : chr  \"M\" \"K\" \"K\" \"K\" ... #>  $ Self-Liking    : int  13 15 19 10 16 12 18 28 10 14 ... #>  $ Self-Competence: int  20 15 26 19 25 17 14 28 19 13 ... #>  $ General Score  : int  33 30 45 29 41 29 32 56 29 27 ..."},{"path":"https://statismike.github.io/stenR/articles/stenR_complete_tour.html","id":"normalize-and-standardize-the-results","dir":"Articles","previous_headings":"","what":"Normalize and standardize the results","title":"Complete tour from data to results","text":"take brief look procedural workflow normalization standardization. noted, verbose less features object-oriented workflow. Nevertheless, recommended useRs don’t much experience utilizing R6 classes. information , read Procedural Object-oriented workflows stenR vignette. process data, stenR need compute object class ScoreTable. similar regular score tables can seen many measures documentations, though computed directly basis available raw scores representative sample. first, initial construction can reused new observations. two step process. Firstly, need compute FrequencyTable object void standard score scale every sub-scale scale. warnings printed : generated raw score values missing -actual minimal maximal values raw scores. rule thumb - wider raw score range smaller less-representative sample , bigger possibility happen. recommended try gather bigger sample happens - unless sure representative enough. defined, can transformed ScreTable objects providing StandardScale object. Objects popular scales psychology already defined - use commonly utilized Standard Ten Scale: STEN point, last thing remains normalize scores. can done using normalize_score() function.","code":"# Create the FrequencyTables SL_ft <- FrequencyTable(summed_data$`Self-Liking`) #> Warning in FrequencyTable(summed_data$`Self-Liking`): There are missing score #> values between minimum and maximum scores. They have been filled automatically. SC_ft <- FrequencyTable(summed_data$`Self-Competence`) #> Warning in FrequencyTable(summed_data$`Self-Competence`): There are missing #> score values between minimum and maximum scores. They have been filled #> automatically. GS_ft <- FrequencyTable(summed_data$`General Score`) #> Warning in FrequencyTable(summed_data$`General Score`): There are missing score #> values between minimum and maximum scores. They have been filled automatically. # Check what is the STEN *StandardScale* definition print(STEN) #> <StandardScale>: 'sten' #> ( M: 5.5; SD: 2; min: 1; max: 10 )  # Calculate the ScoreTables SL_st <- ScoreTable(SL_ft, STEN) SC_st <- ScoreTable(SC_ft, STEN) GS_st <- ScoreTable(GS_ft, STEN) # normalize each of the scale results summed_data$`Self-Liking` <-    normalize_score(summed_data$`Self-Liking`,                   table = SL_st,                   what = \"sten\")  summed_data$`Self-Competence` <-    normalize_score(summed_data$`Self-Competence`,                   table = SC_st,                   what = \"sten\")  summed_data$`General Score` <-    normalize_score(summed_data$`General Score`,                   table = GS_st,                   what = \"sten\")  # check the structure str(summed_data) #> 'data.frame':    103 obs. of  5 variables: #>  $ user_id        : chr  \"damaged_kiwi\" \"unilateralised_anglerfish\" \"technical_anemonecrab\" \"temperate_americancurl\" ... #>  $ sex            : chr  \"M\" \"K\" \"K\" \"K\" ... #>  $ Self-Liking    : num  3 4 5 2 4 3 5 8 2 4 ... #>  $ Self-Competence: num  5 2 7 4 7 3 2 8 4 2 ... #>  $ General Score  : num  4 3 6 3 5 3 4 8 3 2 ..."},{"path":"https://statismike.github.io/stenR/articles/stenR_complete_tour.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Complete tour from data to results","text":", cane end journey. summarize: ScaleSpec() CombScaleSpec() sum_items_to_scale() FrequencyTable() ScoreTable() normalize_score()","code":""},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"procedural-workflow-for-using-stenr-functionality","dir":"Articles","previous_headings":"","what":"Procedural workflow for using stenR functionality","title":"Procedural and Object-oriented workflows of stenR","text":"stenR currently based S3 classes can used purely procedural workflow, described . Exemplary data provided package used:","code":"library(stenR)  # data gathered in Polish sample - 204 summed results of HEXACO-60 questionnaires str(HEXACO_60) #> 'data.frame':    204 obs. of  9 variables: #>  $ user_id: chr  \"neutral_peregrinefalcon\" \"trapeziform_zebradove\" \"polyhedral_solenodon\" \"decrepit_norwayrat\" ... #>  $ sex    : chr  \"F\" \"F\" \"F\" \"F\" ... #>  $ age    : int  26 24 26 25 31 25 62 19 24 26 ... #>  $ HEX_H  : int  42 38 18 21 32 34 37 39 41 30 ... #>  $ HEX_E  : int  33 31 17 24 35 30 37 13 33 24 ... #>  $ HEX_X  : int  34 36 16 29 24 34 39 27 23 34 ... #>  $ HEX_A  : int  36 44 42 22 31 34 23 27 15 21 ... #>  $ HEX_C  : int  36 36 35 43 34 28 41 19 49 38 ... #>  $ HEX_O  : int  31 28 37 47 28 39 44 42 22 38 ..."},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"create-a-frequency-table-object-on-basis-of-some-variable","dir":"Articles","previous_headings":"Procedural workflow for using stenR functionality","what":"1. Create a Frequency Table object on basis of some variable","title":"Procedural and Object-oriented workflows of stenR","text":"Generated warning tells us raw scores min() max() values weren’t represented sample. can see case scores: can also see plotting resulting FrequencyTable:  rule thumb: possible values raw scores can get smaller data, bigger possibility happen. feel sample representative, can ignore . recommended though get varied, greater number observations getting warning.","code":"HEX_H_ft <- FrequencyTable(HEXACO_60$HEX_H) #> Warning in FrequencyTable(HEXACO_60$HEX_H): There are missing score values #> between minimum and maximum scores. They have been filled automatically. HEX_H_ft #> <FrequencyTable> computed on: 204 observations #> range: incomplete (missing raw score values between <min> and <max>)  #>  #>  score  n      freq       quan           Z #>     14  1 0.4901961  0.2450980 -2.81340671 #>     15  1 0.4901961  0.7352941 -2.43954226 #>     16  2 0.9803922  1.4705882 -2.17792307 #>     17  0 0.0000000  1.4705882 -2.17792307 #>     18  3 1.4705882  2.6960784 -1.92746610 #>     19  2 0.9803922  3.9215686 -1.75986103 #>     20  1 0.4901961  4.6568627 -1.67907589 #>     21  3 1.4705882  5.6372549 -1.58597448 #>     22  0 0.0000000  5.6372549 -1.58597448 #>     23  2 0.9803922  6.8627451 -1.48609157 #>     24  3 1.4705882  8.0882353 -1.39916101 #>     25  3 1.4705882  9.5588235 -1.30710672 #>     26  5 2.4509804 11.5196078 -1.19934929 #>     27  8 3.9215686 14.7058824 -1.04913140 #>     28  8 3.9215686 18.6274510 -0.89170883 #>     29 10 4.9019608 23.0392157 -0.73755598 #>     30 14 6.8627451 28.9215686 -0.55567745 #>     31 11 5.3921569 35.0490196 -0.38399738 #>     32  7 3.4313725 39.4607843 -0.26732923 #>     33  9 4.4117647 43.3823529 -0.16664795 #>     34 11 5.3921569 48.2843137 -0.04301914 #>     35 13 6.3725490 54.1666667  0.10463346 #>     36 17 8.3333333 61.5196078  0.29288789 #>     37  7 3.4313725 67.4019608  0.45103991 #>     38 13 6.3725490 72.3039216  0.59189400 #>     39 13 6.3725490 78.6764706  0.79524571 #>     40  5 2.4509804 83.0882353  0.95765790 #>     41  6 2.9411765 85.7843137  1.07067914 #>     42  5 2.4509804 88.4803922  1.19934929 #>     43  2 0.9803922 90.1960784  1.29280523 #>     44  6 2.9411765 92.1568627  1.41570209 #>     45  6 2.9411765 95.0980392  1.65443473 #>     46  3 1.4705882 97.3039216  1.92746610 #>     47  0 0.0000000 97.3039216  1.92746610 #>     48  0 0.0000000 97.3039216  1.92746610 #>     49  2 0.9803922 98.5294118  2.17792307 #>     50  2 0.9803922 99.5098039  2.58266941 which(HEX_H_ft$table$n == 0) #> [1]  4  9 34 35 plot(HEX_H_ft)"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"generate-scoretable-using-frequencytable","dir":"Articles","previous_headings":"Procedural workflow for using stenR functionality","what":"2. Generate ScoreTable using FrequencyTable","title":"Procedural and Object-oriented workflows of stenR","text":"FrequencyTable basis normalizing distribution data. Now, next step standardize using StandardScale generating ScoreTable. StandardScale objects available package. define score scale. can use popular psychology STEN scale calculate scores.  Now, can generate ScoreTable using FrequencyTable scale choosing.  can see shape generated distribution similar distribution associated StandardScale. good sign: number values raw scores appropriate chosen scale. contrast, can see TANINE scale ill choice:  can also define StandardScale object using StandardScale function.","code":"# check out the scale definition STEN #> <StandardScale>: 'sten' #> ( M: 5.5; SD: 2; min: 1; max: 10 ) # see its distribution graphically plot(STEN) HEX_H_st <- ScoreTable(HEX_H_ft, STEN)  plot(HEX_H_st) plot(ScoreTable(HEX_H_ft, TANINE)) new_scale <- StandardScale(\"my_scale\", 10, 3, 0, 20)  # let's see if everything is correct new_scale #> <StandardScale>: 'my_scale' #> ( M: 10; SD: 3; min: 0; max: 20 )  # how does its distribution looks like? plot(new_scale)"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"calculate-score-for-the-new-results","dir":"Articles","previous_headings":"Procedural workflow for using stenR functionality","what":"3. Calculate score for the new results","title":"Procedural and Object-oriented workflows of stenR","text":"Now, ScoreTable created, can use standardize scores! randomly generated ones using normalize_score() function:","code":"set.seed(2137)  # generate some random raw scores of valid values raw_scores <- round(runif(10, min = 10, max = 50), 0)  print(raw_scores) #>  [1] 19 12 14 45 20 22 30 39 33 23  # and now - get the 'STEN' values! normalize_score(   x = raw_scores,   table = HEX_H_st,   what = \"sten\") #>  [1] 2 1 1 9 2 2 4 7 5 3"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"object-oriented-workflow","dir":"Articles","previous_headings":"","what":"Object oriented workflow","title":"Procedural and Object-oriented workflows of stenR","text":"addition procedural workflow described , also R6 class definition prepared handle creation ScoreTables generation normalized scores: CompScoreTable. one useful feature object, mainly ability automatically recalculate ScoreTables based raw score values calculated using standardize method. can helpful inter-session continuity.","code":""},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"initialize-the-object","dir":"Articles","previous_headings":"Object oriented workflow","what":"1. Initialize the object","title":"Procedural and Object-oriented workflows of stenR","text":"object initialization can attach previously calculated FrequencyTables /StandardScales. fully optional, can also done afterwards.","code":"# attach during initialization HexCST <- CompScoreTable$new(   tables = list(HEX_H = HEX_H_ft),   scales = STEN )  # attach later altCST <- CompScoreTable$new() altCST$attach_FrequencyTable(HEX_H_ft, \"HEX_H\") altCST$attach_StandardScale(STEN)  # there are no visible differences in objects structure summary(HexCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>  #> Attached <StandardScales>: #>  name   M SD min max #>  sten 5.5  2   1  10 summary(altCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>  #> Attached <StandardScales>: #>  name   M SD min max #>  sten 5.5  2   1  10"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"expand-compscoretable","dir":"Articles","previous_headings":"Object oriented workflow","what":"2. Expand CompScoreTable","title":"Procedural and Object-oriented workflows of stenR","text":"creation object can expanded FrequencyTables StandardScales. ScoreTables internally recalculated","code":"# add new FrequencyTable HexCST$attach_FrequencyTable(FrequencyTable(HEXACO_60$HEX_C), \"HEX_C\") summary(HexCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>     HEX_C 204   complete #>  #> Attached <StandardScales>: #>  name   M SD min max #>  sten 5.5  2   1  10  # add new StandardScale HexCST$attach_StandardScale(STANINE) summary(HexCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>     HEX_C 204   complete #>  #> Attached <StandardScales>: #>     name   M SD min max #>     sten 5.5  2   1  10 #>  stanine 5.0  2   1   9"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"a--standardize-scores","dir":"Articles","previous_headings":"Object oriented workflow","what":"3a. Standardize scores","title":"Procedural and Object-oriented workflows of stenR","text":"object ready, score standardization may begin. Let’s feed raw scores!","code":"# standardize the Honesty-Humility and Consciousness HexCST$standardize(   data = head(HEXACO_60),   what = \"sten\",   vars = c(\"HEX_H\", \"HEX_C\") ) #>                   user_id sex age HEX_H HEX_E HEX_X HEX_A HEX_C HEX_O #> 1 neutral_peregrinefalcon   F  26     8    33    34    36     6    31 #> 2   trapeziform_zebradove   F  24     7    31    36    44     6    28 #> 3    polyhedral_solenodon   F  26     2    17    16    42     5    37 #> 4      decrepit_norwayrat   F  25     2    24    29    22     8    47 #> 5          unawake_wisent   F  31     5    35    24    31     5    28 #> 6   turophilic_spreadwing   M  25     5    30    34    34     3    39  # you can also do this easily with pipes! HEXACO_60[1:5, c(\"HEX_H\", \"HEX_C\")] |>   # no need to specify 'vars', as the correct columns are already selected   HexCST$standardize(\"sten\") #>   HEX_H HEX_C #> 1     8     6 #> 2     7     6 #> 3     2     5 #> 4     2     8 #> 5     5     5"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"b--automatically-recalculate-scoretables","dir":"Articles","previous_headings":"Object oriented workflow","what":"3b. Automatically recalculate ScoreTables","title":"Procedural and Object-oriented workflows of stenR","text":"score standardization, can also automatically add new raw scores existing frequencies recalculate ScoreTables automatically. done returning values, based recent ScoreTables. can actually use standardize() calc = TRUE just attaching scale scales. ScoreTables generated automatically data standardization - receive data computed ScoreTables","code":"# check the current state of the object summary(HexCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>     HEX_C 204   complete #>  #> Attached <StandardScales>: #>     name   M SD min max #>     sten 5.5  2   1  10 #>  stanine 5.0  2   1   9  # now, standardize and recalculate! HEXACO_60[1:5, c(\"HEX_H\", \"HEX_C\")] |>   HexCST$standardize(\"sten\", calc = TRUE) #>   HEX_H HEX_C #> 1     8     6 #> 2     7     6 #> 3     2     5 #> 4     2     8 #> 5     5     5  # check the new state summary(HexCST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 209 incomplete #>     HEX_C 209   complete #>  #> Attached <StandardScales>: #>     name   M SD min max #>     sten 5.5  2   1  10 #>  stanine 5.0  2   1   9"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"c--export-tables","dir":"Articles","previous_headings":"Object oriented workflow","what":"3c. Export tables","title":"Procedural and Object-oriented workflows of stenR","text":"also option export ScoreTables - either use later procedural way create new CompScoreTable another session - reason also option export FrequencyTables!","code":"# export as ScoreTables st_list <- HexCST$export_ScoreTable() summary(st_list) #>       Length Class      Mode #> HEX_H 3      ScoreTable list #> HEX_C 3      ScoreTable list  # export as FrequencyTables ft_list <- HexCST$export_ScoreTable(strip = T) summary(ft_list) #>       Length Class          Mode #> HEX_H 2      FrequencyTable list #> HEX_C 2      FrequencyTable list"},{"path":"https://statismike.github.io/stenR/articles/stenR_workflows.html","id":"calculate-frequencytable-using-only-distribution-data","dir":"Articles","previous_headings":"","what":"Calculate FrequencyTable using only distribution data","title":"Procedural and Object-oriented workflows of stenR","text":"Ideally, normalization using stenR done using raw, actual data. Unfortunately, often can’t accessed. Alternatively, articles specifying measurement construction often share descriptive statistics results. Using can create Simulated tables:  Simulated class inherited ScoreTable object created basis. Simulated tables can used every way regular ones can one exception: used create CompScoreTable object, raw scores appended kind table standardize() method.","code":"sim_ft <- SimFrequencyTable(min = 10, max = 50, M = 31.04,                              SD = 6.7, skew = -0.3, kurt = 2.89, seed = 2678) #> Constants: Distribution  1   #>  #> Constants calculation time: 0.007 minutes  #> Total Simulation time: 0.007 minutes  class(sim_ft) #> [1] \"FrequencyTable\" \"Simulated\"  plot(sim_ft) SimCST <- CompScoreTable$new(   tables = list(\"simmed\" = sim_ft),   scales = STEN )  SimCST$standardize(   data = data.frame(simmed = round(runif(10, 10, 50), 0)),   what = \"sten\",   calc = TRUE) #> Error: You can't add new raw values to Simulated FrequencyTable"},{"path":"https://statismike.github.io/stenR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michal Kosinski. Author, maintainer.","code":""},{"path":"https://statismike.github.io/stenR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kosinski M (2022). stenR: R6-based Standardization Raw Discrete Scores. R package version 0.5.1, https://statismike.github.io/stenR/.","code":"@Manual{,   title = {stenR: R6-based Standardization of Raw Discrete Scores},   author = {Michal Kosinski},   year = {2022},   note = {R package version 0.5.1},   url = {https://statismike.github.io/stenR/}, }"},{"path":"https://statismike.github.io/stenR/index.html","id":"stenr-","dir":"","previous_headings":"","what":"R6-based Standardization of Raw Discrete Scores ","title":"R6-based Standardization of Raw Discrete Scores ","text":"stenR package tailored mainly users creators psychological questionnaires, though social science researchers survey authors can benefit greatly . provides straightforward framework normalization standardization raw discrete scores standardized scale choosing. follows simple work pattern: create frequency table compute Z-score corresponding raw score create score table using standard scale. provide external raw score recalculated standardized scale Additionally, introduces compatible rest workflow helper functions preprocess data: user answers item, summarized scales/factors score.","code":""},{"path":"https://statismike.github.io/stenR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R6-based Standardization of Raw Discrete Scores ","text":"can install current version GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"StatisMike/stenR\")"},{"path":"https://statismike.github.io/stenR/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"R6-based Standardization of Raw Discrete Scores ","text":"numerous functions S3 classes constructors help normalize standardize discrete data. also special R6 class making whole process organized potential inter-session continuity. methods focusing using raw data available us. Unfortunately, using another author’s questionnaire often don’t raw data available calculating FrequencyTable regular way. Authors usually provide descriptive statistics data, though. can use estimate frequencies use normalize raw scores gathered study.","code":"library(stenR) #> Loading required package: R6  # build-in dataset with questionnaire data summary(HEXACO_60$HEX_C) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   17.00   30.00   35.00   35.42   40.00   50.00  # create STEN score table for variable HEX_C_st <- HEXACO_60$HEX_C |>   FrequencyTable() |>   ScoreTable(STEN)  # use the STEN table to normalize and standardize data HEX_C_sten <- HEXACO_60$HEX_C |>   normalize_score(HEX_C_st, \"sten\")  summary(HEX_C_sten) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.000   4.000   5.000   5.495   7.000  10.000 # inspect the whole dataset for comparison head(HEXACO_60) #>                   user_id sex age HEX_H HEX_E HEX_X HEX_A HEX_C HEX_O #> 1 neutral_peregrinefalcon   F  26    42    33    34    36    36    31 #> 2   trapeziform_zebradove   F  24    38    31    36    44    36    28 #> 3    polyhedral_solenodon   F  26    18    17    16    42    35    37 #> 4      decrepit_norwayrat   F  25    21    24    29    22    43    47 #> 5          unawake_wisent   F  31    32    35    24    31    34    28 #> 6   turophilic_spreadwing   M  25    34    30    34    34    28    39  # initialize the object with some scale attached HEX_ST <- CompScoreTable$new(   scales = STEN )  # you can use the `standardize` method to automatically calculate the tables # during data calculation HEXACO_sten <- HEX_ST$standardize(   HEXACO_60,   # specify the variables to calculate if there are any other in the data.frame   vars = c(\"HEX_H\", \"HEX_E\", \"HEX_X\", \"HEX_A\", \"HEX_C\", \"HEX_O\"),   what = \"sten\",   calc = TRUE)  # inspect the recalculated dataset head(HEXACO_sten) #>                   user_id sex age HEX_H HEX_E HEX_X HEX_A HEX_C HEX_O #> 1 neutral_peregrinefalcon   F  26     8     5     7     8     6     3 #> 2   trapeziform_zebradove   F  24     7     5     7    10     6     2 #> 3    polyhedral_solenodon   F  26     2     2     2    10     5     5 #> 4      decrepit_norwayrat   F  25     2     3     6     3     8     9 #> 5          unawake_wisent   F  31     5     6     4     6     5     2 #> 6   turophilic_spreadwing   M  25     5     5     7     7     3     6  # CompScoreTable object have the table already populated for next data input summary(HEX_ST) #> <CompScoreTable> object #>  #> Attached <ScoreTables>: #>  variable   n      range #>     HEX_H 204 incomplete #>     HEX_E 204 incomplete #>     HEX_X 204 incomplete #>     HEX_A 204 incomplete #>     HEX_C 204   complete #>     HEX_O 204 incomplete #>  #> Attached <StandardScales>: #>  name   M SD min max #>  sten 5.5  2   1  10 simulated_ft <- SimFrequencyTable(   min = 10, max = 50, M = 31.04, SD = 6.7,    skew = -0.3, kurt = 2.89, seed = 2678) #> Constants: Distribution  1   #>  #> Constants calculation time: 0.007 minutes  #> Total Simulation time: 0.008 minutes  plot(simulated_ft) normalize_score(HEXACO_60$HEX_A,                 table = ScoreTable(simulated_ft, STEN),                 \"sten\") |>   summary() #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.000   3.000   5.000   4.892   6.000  10.000"},{"path":"https://statismike.github.io/stenR/index.html","id":"data-preprocessing","dir":"","previous_headings":"","what":"Data preprocessing","title":"R6-based Standardization of Raw Discrete Scores ","text":"Workflow assumes data already preprocessed, summarized score construct presented functions. working actual data, commonly presented answers individual items. needed summarize distinct scales factors. Author may also chose handle NAs way, commonly items need reversing summarizing scale score. steps can achieved using ScaleSpec objects sum_items_to_scale function.","code":"# Answers per item: Self-liking self-competence scale # (dataset included within package) head(SLCS) #>                                   user_id sex age SLCS_1 SLCS_2 SLCS_3 SLCS_4 #> 1                            damaged_kiwi   M  30      4      2      1      2 #> 2               unilateralised_anglerfish   K  31      5      2      2      1 #> 3                   technical_anemonecrab   K  22      4      4      4      4 #> 4                  temperate_americancurl   K  26      5      3      2      2 #> 5 uncontradictious_irishredandwhitesetter   K  22      5      2      3      4 #> 6              simaroubaceous_acornweevil   K  17      5      3      1      2 #>   SLCS_5 SLCS_6 SLCS_7 SLCS_8 SLCS_9 SLCS_10 SLCS_11 SLCS_12 SLCS_13 SLCS_14 #> 1      2      4      4      4      2       4       1       4       4       2 #> 2      2      4      4      5      3       4       1       2       5       1 #> 3      4      5      4      4      2       3       2       4       5       3 #> 4      1      5      5      5      1       4       1       3       4       2 #> 5      2      5      3      4      3       4       1       3       3       4 #> 6      2      5      5      5      1       4       2       2       4       1 #>   SLCS_15 SLCS_16 #> 1       5       4 #> 2       4       5 #> 3       4       5 #> 4       4       4 #> 5       4       5 #> 6       3       4  # Scale specification for each of subscales and general score: ## Self-Liking specification SL_spec <- ScaleSpec(   name = \"SL\",   item_names = paste(\"SLCS\", c(1, 3, 5, 6, 7, 9, 11, 15), sep = \"_\"),   reverse = paste(\"SLCS\", c(1, 6, 7, 15), sep = \"_\"),   min = 1,   max = 5)  ## Self-Competence specification SC_spec <- ScaleSpec(   name = \"SC\",   item_names = paste(\"SLCS\", c(2, 4, 8, 10, 12, 13, 14, 16), sep = \"_\"),   reverse = paste(\"SLCS\", c(8, 10, 13), sep = \"_\"),   min = 1,   max = 5)  ## General Score specification GS_spec <- CombScaleSpec(   name = \"GS\",   SL_spec,   SC_spec)  # Sum the data SLCS_summed <- sum_items_to_scale(SLCS, SL_spec, SC_spec, GS_spec, retain = c(\"user_id\", \"sex\", \"age\")) head(SLCS_summed) #>                                   user_id sex age SL SC GS #> 1                            damaged_kiwi   M  30 13 20 33 #> 2               unilateralised_anglerfish   K  31 15 15 30 #> 3                   technical_anemonecrab   K  22 19 26 45 #> 4                  temperate_americancurl   K  26 10 19 29 #> 5 uncontradictious_irishredandwhitesetter   K  22 16 25 41 #> 6              simaroubaceous_acornweevil   K  17 12 17 29"},{"path":"https://statismike.github.io/stenR/reference/CombScaleSpec.html","id":null,"dir":"Reference","previous_headings":"","what":"Combined Scale Specification — CombScaleSpec","title":"Combined Scale Specification — CombScaleSpec","text":"Combine multiple ScaleSpec objects one regards sum_items_to_scales() function. Useful one scale factor contains items different possible values hierarchy scale factors. Also allows combining CombScaleSpec object, factor structure deeper hierarchy.","code":""},{"path":"https://statismike.github.io/stenR/reference/CombScaleSpec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combined Scale Specification — CombScaleSpec","text":"","code":"CombScaleSpec(name, ..., reverse = character(0))  # S3 method for CombScaleSpec print(spec)  # S3 method for CombScaleSpec summary(spec)"},{"path":"https://statismike.github.io/stenR/reference/CombScaleSpec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combined Scale Specification — CombScaleSpec","text":"name Name combined scale factor ... ScaleSpec CombScaleSpec objects reverse character vector containing names underlying subscales factors need reversed spec CombScaleSpec object","code":""},{"path":"https://statismike.github.io/stenR/reference/CombScaleSpec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combined Scale Specification — CombScaleSpec","text":"CombScaleSpec object","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/CombScaleSpec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combined Scale Specification — CombScaleSpec","text":"","code":"# ScaleSpec objects to Combine  first_scale <- ScaleSpec(   name = \"First Scale\",   item_names = c(\"Item_1\", \"Item_2\"),   min = 1,   max = 5 )  second_scale <- ScaleSpec(   name = \"Second Scale\",   item_names = c(\"Item_3\", \"Item_4\"),   min = 0,   max = 7,   reverse = \"Item_3\" )  third_scale <- ScaleSpec(   name = \"Third Scale\",   item_names = c(\"Item_5\", \"Item_6\"),   min = 1,   max = 5 )  # You can combine few ScaleSpec objects into CombScaleSpec  first_comb <- CombScaleSpec(   name = \"First Comb\",   first_scale,   second_scale,   reverse = \"Second Scale\" )  print(first_comb) #> <CombScaleSpec>: 'First Comb' #> No. items total: 4 #>  #> Underlying objects: #> <ScaleSpec>: First Scale #> <ScaleSpec>: Second Scale <reversed>  # And also other CombScaleSpec objects!  second_comb <- CombScaleSpec(   name = \"Second Comb\",   first_comb,   third_scale )  print(second_comb) #> <CombScaleSpec>: 'Second Comb' #> No. items total: 6 #>  #> Underlying objects: #> <CombScaleSpec>: First Comb #> <ScaleSpec>: Third Scale"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Computable ScoreTable class. can compute store ScoreTables multiple variables containing raw score results. computation, also used compute new standardized scores provided raw scores integrate stored tables. summary() function can used get general information CompScoreTable object.","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"CompScoreTable$new() CompScoreTable$attach_StandardScale() CompScoreTable$attach_FrequencyTable() CompScoreTable$export_ScoreTable() CompScoreTable$standardize() CompScoreTable$clone()","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Initialize CompScoreTable object. can attach one many StandardScale FrequencyTable objects","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$new(tables = NULL, scales = NULL)"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"tables Named list FrequencyTable objects attached. Names indicate name variable table calculated. Defaults NULL, tables available beginning. scales StandardScale object list objects attached. used calculation ScoreTables. Defaults NULL, scales wil available beginning.","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"FrequencyTable StandardScale objects can attached appropriate methods object initialization.","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"CompScoreTable object","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-attach-standardscale-","dir":"Reference","previous_headings":"","what":"Method attach_StandardScale()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Attach new scale object. ScoreTables already computed, score newly-attached scale computed automatically.","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$attach_StandardScale(scale, overwrite = FALSE)"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"scale StandardScale object defining scale overwrite boolean indicating definition scale name overwritten","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-attach-frequencytable-","dir":"Reference","previous_headings":"","what":"Method attach_FrequencyTable()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Attach previously generated FrequencyTable given variable. ScoreTable containing every attached scale calulcated automatically based every new FrequencyTable.","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$attach_FrequencyTable(ft, var, if_exists = \"stop\")"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"ft FrequencyTable attached var String name variable if_exists Action taken FrequencyTable given variable already exists object. stop DEFAULT: anything append recalculates existing table replace replaces existing table","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-export-scoretable-","dir":"Reference","previous_headings":"","what":"Method export_ScoreTable()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Export list ScoreTables object","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$export_ScoreTable(vars = NULL, strip = FALSE)"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"vars Names variables get tables. left NULL default - get . strip logical indicating ScoreTables stripped FrequencyTables export. Defaults FALSE","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"list ScoreTable FrequencyTable object","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-standardize-","dir":"Reference","previous_headings":"","what":"Method standardize()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"Compute standardize scores data.frame raw scores. Additionally, raw scores can used recalculate ScoreTables computing (using calc = T).","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$standardize(data, what, vars = names(data), calc = FALSE)"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"data data.frame containing raw scores. values get. One either: quan - quantile raw score distribution Z - normalized Z score raw scores name scale attached CompScoreTable object vars vector variable names taken account calc ScoreTables computed (recalculated, already provided?). Default TRUE","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"data.frame standardized values","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"objects class cloneable method.","code":""},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"","code":"CompScoreTable$clone(deep = FALSE)"},{"path":"https://statismike.github.io/stenR/reference/CompScoreTable.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"R6 class for producing easily re-computable ScoreTable — CompScoreTable","text":"deep Whether make deep clone.","code":""},{"path":"https://statismike.github.io/stenR/reference/FrequencyTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a FrequencyTable — FrequencyTable","title":"Create a FrequencyTable — FrequencyTable","text":"Normalizes distribution raw scores. can used construct ScoreTable() use StandardScale() normalize standardize raw discrete scores. plot.FrequencyTable method requires ggplot2 package installed.","code":""},{"path":"https://statismike.github.io/stenR/reference/FrequencyTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a FrequencyTable — FrequencyTable","text":"","code":"FrequencyTable(data)  # S3 method for FrequencyTable print(ft, max = NULL)  # S3 method for FrequencyTable plot(ft)  # S3 method for FrequencyTable summary(ft)"},{"path":"https://statismike.github.io/stenR/reference/FrequencyTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a FrequencyTable — FrequencyTable","text":"data vector raw scores. Double values coerced integer ft FrequencyTable object max numeric NULL, specifying maximal number entries printed. default, NULL, getOption(\"max.print\") used.","code":""},{"path":"https://statismike.github.io/stenR/reference/FrequencyTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a FrequencyTable — FrequencyTable","text":"FrequencyTable object. Consists : table: data.frame number observations (n), frequency sample (freq), quantile (quan) normalized Z-score (Z) point raw score status: list containing total number simulated observations (n) information raw scores range completion (range): complete incomplete","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/HEXACO_60.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data of HEXACO-60 questionnaire results (summed scales) — HEXACO_60","title":"Sample data of HEXACO-60 questionnaire results (summed scales) — HEXACO_60","text":"Dataset containing summed scale scores HEXACO-60 questionnaire. obtained 2020 study Polish incidental sample.","code":""},{"path":"https://statismike.github.io/stenR/reference/HEXACO_60.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample data of HEXACO-60 questionnaire results (summed scales) — HEXACO_60","text":"","code":"HEXACO_60"},{"path":"https://statismike.github.io/stenR/reference/HEXACO_60.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data of HEXACO-60 questionnaire results (summed scales) — HEXACO_60","text":"data frame 204 rows 9 variables user_id identity anonimized 'ids::adjective_animal' sex sex participant ('M'ale, 'F'emale 'O'ther) age age participant (15--62) HEX_H Honesty-Humility raw score (14--50) HEX_E Emotionality raw score (10--47) HEX_X eXtraversion raw score (11--46) HEX_A Agreeableness raw score (12--45) HEX_C Consciousness raw score (17--50) HEX_O Openness Experience raw score (18--50)","code":""},{"path":"https://statismike.github.io/stenR/reference/HEXACO_60.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample data of HEXACO-60 questionnaire results (summed scales) — HEXACO_60","text":"HEXACO scales consists 10 items responses numeric values 1-5 (absolute min max 10-50)","code":""},{"path":"https://statismike.github.io/stenR/reference/SLCS.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data of SLCS questionnaire results (item scores) — SLCS","title":"Sample data of SLCS questionnaire results (item scores) — SLCS","text":"Dataset containing individual items answers SLCS questionnaire. obtained 2020 study Polish incidental sample.","code":""},{"path":"https://statismike.github.io/stenR/reference/SLCS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample data of SLCS questionnaire results (item scores) — SLCS","text":"","code":"SLCS"},{"path":"https://statismike.github.io/stenR/reference/SLCS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample data of SLCS questionnaire results (item scores) — SLCS","text":"data frame 103 rows 19 variables user_id identity anonimized 'ids::adjective_animal' sex sex participant ('M'ale, 'F'emale 'O'ther) age age participant (15--68) SLCS_1 SLCS_16 Score measure items. (1--5)","code":""},{"path":"https://statismike.github.io/stenR/reference/SLCS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample data of SLCS questionnaire results (item scores) — SLCS","text":"SLCS item responses can take integer values 1-5. measure consists two sub-scales: Self-Liking Self-Competence, General Score can also calculated. item numbers used sub-scale (R near number means item need reversed.) Self-Liking: 1R, 3, 5, 6R, 7R, 9, 11, 15R Self-Competence: 2, 4, 8R, 10R, 12, 13R, 14, 16 General Score: items (need reversed sub-scales)","code":""},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale Specification object — ScaleSpec","title":"Scale Specification object — ScaleSpec","text":"Object containing scale factor specification data. describes scale factor, regard items source data part , need summed reverse scoring, handle NAs. used sum_items_to_scale() function preprocess item data.","code":""},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale Specification object — ScaleSpec","text":"","code":"ScaleSpec(   name,   item_names,   min,   max,   reverse = character(0),   na_strategy = c(\"asis\", \"mean\", \"median\", \"mode\"),   na_value = as.integer(NA),   na_value_custom )  # S3 method for ScaleSpec print(spec)  # S3 method for ScaleSpec summary(spec)"},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale Specification object — ScaleSpec","text":"name character name scale/factor item_names character vector containing names items scale/factor consists . min, max integer containing default minimal/maximal value answer item can scored . reverse character vector containing names items need reversed scale/factor summing. Reversed using default min max values. na_strategy character vector specifying strategy taken filling NA. Defaults \"asis\" , options \"mean\", \"median\" \"mode\". Strategies explained details section. na_value integer value input missing values default. Defaults .integer(NA). na_value_custom need specific questions gives specific values place NAs, provide named integer vector . Names names questons. spec ScaleSpec object","code":""},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale Specification object — ScaleSpec","text":"object ScaleSpec class","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"na-imputation","dir":"Reference","previous_headings":"","what":"NA imputation","title":"Scale Specification object — ScaleSpec","text":"specifies NA values treated sum_items_to_scales() function run. asis strategy literal: values specified na_value na_value_custom used without changes. mean, median mode functional strategies. work rowwise basis, appropriate value every observation used. values provided check mean, median mode, value provided na_value na_value_custom used. values mean median rounded imputation.","code":""},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"order-of-operations","dir":"Reference","previous_headings":"","what":"Order of operations","title":"Scale Specification object — ScaleSpec","text":"item reversion functional NAs imputation literal NAs imputation","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/ScaleSpec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale Specification object — ScaleSpec","text":"","code":"# simple scale specification  simple_scaleSpec <- ScaleSpec(   name = \"simple\",   # scale consists of 5 items   item_names = c(\"item_1\", \"item_2\", \"item_3\", \"item_4\", \"item_5\"),   # item scores can take range of values: 1-5   min = 1,   max = 5,   # item 2 and 5 need to be reversed   reverse = c(\"item_2\", \"item_5\"))  print(simple_scale) #> Error in print(simple_scale): object 'simple_scale' not found  # scale specification with literal NA imputation strategy   asis_scaleSpec <- ScaleSpec(   name = \"w_asis\",   item_names = c(\"item_1\", \"item_2\", \"item_3\", \"item_4\", \"item_5\"),   min = 1,   max = 5,   reverse = \"item_2\",   # na values by default will be filled with `3`   na_value = 3,   # except for item_4, where they will be filled with `2`   na_value_custom = c(item_4 = 2) )  print(asis_scaleSpec) #> <ScaleSpec>: 'w_asis' #> No. items: 5 (1 reversed) #> NA imputation method: asis  #> NA literal value: 3   # scale specification with functional NA imputation strategy  func_scaleSpec <- ScaleSpec(   name = \"w_func\",   item_names = c(\"item_1\", \"item_2\", \"item_3\", \"item_4\", \"item_5\"),   min = 1,   max = 5,   reverse = \"item_2\",   # strategies available are 'mean', 'median' and 'mode'   na_strategy = \"mean\" )  print(func_scaleSpec) #> <ScaleSpec>: 'w_func' #> No. items: 5 (1 reversed) #> NA imputation method: mean  #> NA literal value: NA"},{"path":"https://statismike.github.io/stenR/reference/ScoreTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a ScoreTable — ScoreTable","title":"Create a ScoreTable — ScoreTable","text":"Creates table calculate scores specified standardized scale discrete raw score. Uses normalization provided FrequencyTable scale definition created StandardScale. creation can used normalize standardize raw scores normalize_score. plot.ScoreTable method requires ggplot2 package installed.","code":""},{"path":"https://statismike.github.io/stenR/reference/ScoreTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a ScoreTable — ScoreTable","text":"","code":"ScoreTable(ft, scale)  # S3 method for ScoreTable print(st, max = NULL)  # S3 method for ScoreTable plot(st, scale_name = NULL)"},{"path":"https://statismike.github.io/stenR/reference/ScoreTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a ScoreTable — ScoreTable","text":"ft FrequencyTable object scale StandardScale object list multiple StandardScale objects st ScoreTable object max numeric NULL, specifying maximal number entries printed. default, NULL, getOption(\"max.print\") used. scale_name scores multiple scales available, provide name scale plotting.","code":""},{"path":"https://statismike.github.io/stenR/reference/ScoreTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a ScoreTable — ScoreTable","text":"object class ScoreTable. Consists : table: data.frame containing point raw score: number observations (n), frequency sample (freq), quantile (quan), normalized Z-score (Z), score transformed every provided StandardScales status: list containing total number simulated observations (n) information raw scores range completion (range): complete incomplete scale: named list attached StandardScale objects","code":""},{"path":"https://statismike.github.io/stenR/reference/ScoreTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a ScoreTable — ScoreTable","text":"","code":"# firstly compute FrequencyTable for a variable ft <- FrequencyTable(HEXACO_60$HEX_A) #> Warning: There are missing score values between minimum and maximum scores. They have been filled automatically.  # then create a ScoreTable st <- ScoreTable(ft, STEN)  # ScoreTable is ready to use! st #> <ScoreTable> computed on: 204 observations #>  #>  score  n      freq       quan           Z sten #>     12  1 0.4901961  0.2450980 -2.81340671    1 #>     13  1 0.4901961  0.7352941 -2.43954226    1 #>     14  0 0.0000000  0.7352941 -2.43954226    1 #>     15  2 0.9803922  1.4705882 -2.17792307    1 #>     16  1 0.4901961  2.2058824 -2.01297132    1 #>     17  3 1.4705882  3.1862745 -1.85409556    2 #>     18  4 1.9607843  4.9019608 -1.65443473    2 #>     19  4 1.9607843  6.8627451 -1.48609157    3 #>     20  3 1.4705882  8.5784314 -1.36718085    3 #>     21  7 3.4313725 11.0294118 -1.22496546    3 #>     22 11 5.3921569 15.4411765 -1.01769373    3 #>     23 11 5.3921569 20.8333333 -0.81221780    4 #>     24  9 4.4117647 25.7352941 -0.65152773    4 #>     25  5 2.4509804 29.1666667 -0.54852228    4 #>     26  7 3.4313725 32.1078431 -0.46468526    5 #>     27  8 3.9215686 35.7843137 -0.36422999    5 #>     28 13 6.3725490 40.9313725 -0.22931068    5 #>     29 13 6.3725490 47.3039216 -0.06763219    5 #>     30 16 7.8431373 54.4117647  0.11081291    6 #>     31 14 6.8627451 61.7647059  0.29930691    6 #>     32  9 4.4117647 67.4019608  0.45103991    6 #>     33 13 6.3725490 72.7941176  0.60659812    7 #>     34 13 6.3725490 79.1666667  0.81221780    7 #>     35  7 3.4313725 84.0686275  0.99728241    7 #>     36  5 2.4509804 87.0098039  1.12685469    8 #>     37  4 1.9607843 89.2156863  1.23808034    8 #>     38  7 3.4313725 91.9117647  1.39916101    8 #>     39  3 1.4705882 94.3627451  1.58597448    9 #>     40  3 1.4705882 95.8333333  1.73166440    9 #>     41  3 1.4705882 97.3039216  1.92746610    9 #>     42  2 0.9803922 98.5294118  2.17792307   10 #>     43  0 0.0000000 98.5294118  2.17792307   10 #>     44  1 0.4901961 99.2647059  2.43954226   10 #>     45  1 0.4901961 99.7549020  2.81340671   10 #>  #>  #> Used StandardScales: #> <StandardScale>: 'sten' #> ( M: 5.5; SD: 2; min: 1; max: 10 ) #>"},{"path":"https://statismike.github.io/stenR/reference/SimFrequencyTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate FrequencyTable using simulated distribution — SimFrequencyTable","title":"Generate FrequencyTable using simulated distribution — SimFrequencyTable","text":"always best use raw scores computing FrequencyTable. always available - case, function can used simulate distribution given descriptive statistics. simulation always treated estimate. distribution generated using Fleishmann method SimMultiCorrData::nonnormvar1() function used. SimMultiCorrData package needs installed.","code":""},{"path":"https://statismike.github.io/stenR/reference/SimFrequencyTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate FrequencyTable using simulated distribution — SimFrequencyTable","text":"","code":"SimFrequencyTable(min, max, M, SD, skew = 0, kurt = 3, n = 10000, seed = NULL)"},{"path":"https://statismike.github.io/stenR/reference/SimFrequencyTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate FrequencyTable using simulated distribution — SimFrequencyTable","text":"min minimum value raw score max maximum value raw score M mean raw scores distribution SD standard deviation raw scores distribution skew skewness raw scores distribution. Defaults 0 normal distribution kurt kurtosis raw scores distribution. Defaults 3 normal distribution n number observations simulate. Defaults 10000, greater values used generate better estimates. Final number observations generated Frequency Table may less - values lower min higher max filtered . seed seed value random number generation","code":""},{"path":"https://statismike.github.io/stenR/reference/SimFrequencyTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate FrequencyTable using simulated distribution — SimFrequencyTable","text":"FrequencyTable object created simulated data. Consists : table: data.frame number observations (n), frequency sample (freq), quantile (quan) normalized Z-score (Z) point raw score status: list containing total number simulated observations (n) information raw scores range completion (range): complete incomplete","code":""},{"path":"https://statismike.github.io/stenR/reference/StandardScale.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify standard scale — StandardScale","title":"Specify standard scale — StandardScale","text":"StandardScale objects used ScoreTable objects recalculate FrequencyTable standardized scale score. StandardScale defaults available. Check default_scales help page information. Plot method requires ggplot2 package installed.","code":""},{"path":"https://statismike.github.io/stenR/reference/StandardScale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify standard scale — StandardScale","text":"","code":"StandardScale(name, M, SD, min, max)  # S3 method for StandardScale print(object)  # S3 method for StandardScale plot(scale, n = 1000)"},{"path":"https://statismike.github.io/stenR/reference/StandardScale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify standard scale — StandardScale","text":"name Name scale M Mean scale SD Standard deviation scale min Minimal value scale takes max Maximal value scale takes object object summary desired. scale StandardScale object n Number points plot generates. higher number, detailed plots. Default 1000 nicely detailed plot.","code":""},{"path":"https://statismike.github.io/stenR/reference/StandardScale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify standard scale — StandardScale","text":"StandardScale object","code":""},{"path":"https://statismike.github.io/stenR/reference/attach_scales.html","id":null,"dir":"Reference","previous_headings":"","what":"Attach additional StandardScale to already created ScoreTable — attach_scales","title":"Attach additional StandardScale to already created ScoreTable — attach_scales","text":"Attach additional StandardScale already created ScoreTable","code":""},{"path":"https://statismike.github.io/stenR/reference/attach_scales.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attach additional StandardScale to already created ScoreTable — attach_scales","text":"","code":"attach_scales(st, scale)"},{"path":"https://statismike.github.io/stenR/reference/attach_scales.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attach additional StandardScale to already created ScoreTable — attach_scales","text":"st ScoreTable object scale StandardScale object list multiple StandardScale objects","code":""},{"path":"https://statismike.github.io/stenR/reference/attach_scales.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Attach additional StandardScale to already created ScoreTable — attach_scales","text":"","code":"# having a ScoreTable with one StandardScale attached st <- ScoreTable(FrequencyTable(HEXACO_60$HEX_C), STEN) st$scale #> $sten #> <StandardScale>: 'sten' #> ( M: 5.5; SD: 2; min: 1; max: 10 ) #>  names(st$table) #> [1] \"score\" \"n\"     \"freq\"  \"quan\"  \"Z\"     \"sten\"   # possibly attach more scales to ScoreTable st <- attach_scales(st, list(STANINE, WECHSLER_IQ)) st$scale #> $sten #> <StandardScale>: 'sten' #> ( M: 5.5; SD: 2; min: 1; max: 10 ) #>  #> $stanine #> <StandardScale>: 'stanine' #> ( M: 5; SD: 2; min: 1; max: 9 ) #>  #> $wechslerIQ #> <StandardScale>: 'wechslerIQ' #> ( M: 100; SD: 15; min: 40; max: 160 ) #>  names(st$table) #> [1] \"score\"      \"n\"          \"freq\"       \"quan\"       \"Z\"          #> [6] \"sten\"       \"stanine\"    \"wechslerIQ\""},{"path":"https://statismike.github.io/stenR/reference/default_scales.html","id":null,"dir":"Reference","previous_headings":"","what":"Default Standard Scales — default_scales","title":"Default Standard Scales — default_scales","text":"StandardScale objects pre-defined usage. create , use StandardScale() function. STEN: M: 5.5, SD: 2, min: 1, max: 10 STANINE: M: 5, SD: 2, min: 1, max: 9 TANINE: M: 50, SD: 10, min: 1, max: 100 TETRONIC: M: 10, SD: 4, min: 0, max: 20 WECHSLER_IQ: M: 100, SD: 15, min: 40, max: 160","code":""},{"path":"https://statismike.github.io/stenR/reference/normalize_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize raw scores — normalize_score","title":"Normalize raw scores — normalize_score","text":"Use computed FrequencyTable ScoreTable normalize provided raw scores.","code":""},{"path":"https://statismike.github.io/stenR/reference/normalize_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize raw scores — normalize_score","text":"","code":"normalize_score(x, table, what)"},{"path":"https://statismike.github.io/stenR/reference/normalize_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize raw scores — normalize_score","text":"x vector raw scores normalize table FrequencyTable ScoreTable object values get. One either: quan - quantile x raw score distribution Z - normalized Z score x raw score name scale calculated StandardScale provided x argument","code":""},{"path":"https://statismike.github.io/stenR/reference/normalize_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize raw scores — normalize_score","text":"Numeric vector values specified argument","code":""},{"path":"https://statismike.github.io/stenR/reference/normalize_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize raw scores — normalize_score","text":"","code":"# normalize with FrequencyTable ft <- FrequencyTable(HEXACO_60$HEX_H) #> Warning: There are missing score values between minimum and maximum scores. They have been filled automatically.  normalizeScore(HEXACO_60$HEX_H[1:5], ft) #> Error in normalizeScore(HEXACO_60$HEX_H[1:5], ft): could not find function \"normalizeScore\"  # normalize with ScoreTable st <- ScoreTable(ft, list(STEN, STANINE))  normalizeScore(HEXACO_60$HEX_H[1:5], st, \"sten\") #> Error in normalizeScore(HEXACO_60$HEX_H[1:5], st, \"sten\"): could not find function \"normalizeScore\" normalizeScore(HEXACO_60$HEX_H[1:5], st, \"stanine\") #> Error in normalizeScore(HEXACO_60$HEX_H[1:5], st, \"stanine\"): could not find function \"normalizeScore\""},{"path":"https://statismike.github.io/stenR/reference/strip_ScoreTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Revert the ScoreTable back to FrequencyTable object. — strip_ScoreTable","title":"Revert the ScoreTable back to FrequencyTable object. — strip_ScoreTable","text":"Revert ScoreTable back FrequencyTable object.","code":""},{"path":"https://statismike.github.io/stenR/reference/strip_ScoreTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Revert the ScoreTable back to FrequencyTable object. — strip_ScoreTable","text":"","code":"strip_ScoreTable(st)"},{"path":"https://statismike.github.io/stenR/reference/strip_ScoreTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Revert the ScoreTable back to FrequencyTable object. — strip_ScoreTable","text":"st ScoreTable object","code":""},{"path":"https://statismike.github.io/stenR/reference/strip_ScoreTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Revert the ScoreTable back to FrequencyTable object. — strip_ScoreTable","text":"","code":"# having a ScoreTable object st <- ScoreTable(FrequencyTable(HEXACO_60$HEX_X), TANINE) #> Warning: There are missing score values between minimum and maximum scores. They have been filled automatically. class(st) #> [1] \"ScoreTable\"  # revert it back to the FrequencyTable ft <- strip_ScoreTable(st) class(ft) #> [1] \"FrequencyTable\""},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum up discrete raw data — sum_items_to_scale","title":"Sum up discrete raw data — sum_items_to_scale","text":"Helper function sum-- needed - automatically reverse discrete raw item values scale factor measuring.","code":""},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum up discrete raw data — sum_items_to_scale","text":"","code":"sum_items_to_scale(data, ..., retain = FALSE, .dots)"},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum up discrete raw data — sum_items_to_scale","text":"data data.frame object containing numerical values items data ... objects class ScaleSpec. item names ScaleSpec found data, summed items available returned data.frame column named ScaleSpec name value. retain either boolean: TRUE columns data retained, FALSE none, character vector names columns retained .dots ScaleSpec objects provided list, instead individually ....","code":""},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum up discrete raw data — sum_items_to_scale","text":"object class data.frame","code":""},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sum up discrete raw data — sum_items_to_scale","text":"summing raw discrete values scale factor score done according provided specifications utilizing ScaleSpec() objects. information refer constructor help page.","code":""},{"path":[]},{"path":"https://statismike.github.io/stenR/reference/sum_items_to_scale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sum up discrete raw data — sum_items_to_scale","text":"","code":"# create the Scale Specifications for SLCS dataset ## Self-Liking specification SL_spec <- ScaleSpec(   name = \"Self-Liking\",   item_names = paste(\"SLCS\", c(1, 3, 5, 6, 7, 9, 11, 15), sep = \"_\"),   reverse = paste(\"SLCS\", c(1, 6, 7, 15), sep = \"_\"),   min = 1,   max = 5)  ## Self-Competence specification SC_spec <- ScaleSpec(   name = \"Self-Competence\",   item_names = paste(\"SLCS\", c(2, 4, 8, 10, 12, 13, 14, 16), sep = \"_\"),   reverse = paste(\"SLCS\", c(8, 10, 13), sep = \"_\"),   min = 1,   max = 5)  ## General Score specification GS_spec <- CombScaleSpec(   name = \"General Score\",   SL_spec,   SC_spec)  # Sum the raw item scores to raw scale scores SLCS_summed <- sum_items_to_scale(SLCS, SL_spec, SC_spec, GS_spec, retain = \"user_id\") summary(SLCS_summed) #>    user_id           Self-Liking    Self-Competence General Score   #>  Length:103         Min.   : 8.00   Min.   :10.00   Min.   :20.00   #>  Class :character   1st Qu.:15.00   1st Qu.:19.00   1st Qu.:35.00   #>  Mode  :character   Median :19.00   Median :22.00   Median :42.00   #>                     Mean   :20.53   Mean   :22.15   Mean   :42.68   #>                     3rd Qu.:24.00   3rd Qu.:25.00   3rd Qu.:48.50   #>                     Max.   :40.00   Max.   :33.00   Max.   :72.00"}]
