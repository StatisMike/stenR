---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  fig.width = 6,
  fig.height = 4
)
Sys.setenv(LANGUAGE='en')
```

# stenR

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-blue.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![codecov](https://codecov.io/gh/StatisMike/stenR/branch/master/graph/badge.svg?token=H62VR1J454)](https://codecov.io/gh/StatisMike/stenR)
<!-- badges: end -->

`stenR` is a package tailored mainly for creators of psychological questionnaires,
though other social science researchers and survey authors can benefit greatly
from it.

It provides straightforward framework for normalization and standardization
of raw discrete scores to standardized scale of your choosing. It follows simple
work pattern:

- create frequency table and compute Z-score corresponding to each raw score
- create score table using some standard scale.
- provide external raw score to be recalculated to standardized scale.

## Installation

You can install the current version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("StatisMike/stenR")
```

## Usage

There are numerous functions and `S3` classes constructors to help normalize
and standardize discrete data.

```{r procedural_use}
library(stenR)

# build-in dataset with questionnaire data
summary(HEXACO_60$HEX_C)

# create STEN score table for variable
HEX_C_st <- HEXACO_60$HEX_C |>
  FrequencyTable() |>
  ScoreTable(STEN)

# use the STEN table to normalize and standardize data
HEX_C_sten <- HEXACO_60$HEX_C |>
  normalize_score(HEX_C_st, "sten")

summary(HEX_C_sten)
```

There is also a special `R6` class making the whole process more organized 
with potential inter-session continuity.

```{r oop_use}
# inspect the whole dataset for comparison
head(HEXACO_60)

# initialize the object with some scale attached
HEX_ST <- CompScoreTable$new(
  scales = STEN
)

# you can use the `standardize` method to automatically calculate the tables
# during data calculation
HEXACO_sten <- HEX_ST$standardize(
  HEXACO_60,
  # specify the variables to calculate if there are any other in the data.frame
  vars = c("HEX_H", "HEX_E", "HEX_X", "HEX_A", "HEX_C", "HEX_O"),
  what = "sten",
  calc = TRUE)

# inspect the recalculated dataset
head(HEXACO_sten)

# CompScoreTable object have the table already populated for next data input
summary(HEX_ST)
```

Above methods were focusing on using raw data available to us. Unfortunately,
when using another author's questionnaire we often don't have their raw data
available for calculating the *FrequencyTable* in regular way.

Authors usually provide descriptive statistics about their data, though.
We can use it to estimate the frequencies and use it to normalize raw scores
gathered in our study.

```{r simulated_use}
simulated_ft <- SimFrequencyTable(
  min = 10, max = 50, M = 31.04, SD = 6.7, 
  skew = -0.3, kurt = 2.89, seed = 2678)

plot(simulated_ft)

normalize_score(HEXACO_60$HEX_A,
                table = ScoreTable(simulated_ft, STEN),
                "sten") |>
  summary()
```